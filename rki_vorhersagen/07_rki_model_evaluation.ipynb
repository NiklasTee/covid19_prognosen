{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#f37726\">07 RKI Model Evaluation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ziele des Notebooks:**\n",
    "- Benchmarks der Modelle verlgeichen\n",
    "- St√§rken und Schw√§chen der Methoden beschreiben\n",
    "- M√∂gliche Einflussfaktoren identifizieren\n",
    "- Das beste Vorhersagemodell ausw√§hlen\n",
    "- Ausblick √ºber weitere M√∂glichkeiten zur Optimierung geben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Tabelle fasst die Ergebnisse der Modelle in den durchgef√ºhrten Vorhersagen zusammen (eine pdf-Datei mit h√∂herer Aufl√∂sung befindet sich im 'visualization'-Ordner):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Benchmark](visualization/rki_evaluation_benchmark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je Zeile ist das Modell hervorgehoben, welches die besten Evaluierungsma√üe erreicht hat. Sowohl bei der Single-Period-Vorhersage als auch bei der Multi-Period-Vorhersage hat das RNN am √∂ftesten die besten Werte erreicht. Bei der Total-Period-Vorhersage hat √ºberraschenderweise das naive Modell am Besten abgeschnitten. Es folgt eine kurze Auswertung f√ºr jedes Modell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Na√Øve / SNa√Øve**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die konservative Vorhersage ohne Ber√ºcksichtung von Trends ist nicht per se schlecht. Insbesondere wenn die Zeitreihe station√§r  und der Vorhersagezeitraum lang ist, kann der Ansatz es mit komplexen Vorhersagemodellen aufnehmen. Da von den Fallzahlen der Vortage abstrahiert wird (nur Wert der letzten Woche), sind die kurzfristigen Vorhersagen eher ungenau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) SNa√Øve mit w√∂chentlicher Trendkomponente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse des naiven Modells mit w√∂chentlicher Trendkomponente wurden durch gelegentliche Ausrei√üer bei der Vorhersage verzerrt. Au√üergew√∂hnlich starke Ver√§nderungen der Fallzahlen, zum Beispiel durch Feiertage, hatten vereinzelt enormen Einfluss auf die Vorhersage. Gl√§ttungsfaktoren oder Minimal- bzw. Maximalwertbegrenzungen k√∂nnten hier die Vorhersageg√ºte verbessern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Exponentielle Gl√§ttung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vorhersagen des  Gl√§ttungsmodells 1. Ordnung waren im Durchschnitt am ungenauesten.Der Gl√§ttungsfaktor ùõº w√§re Ansatzpunkt f√ºr eine Optimierung. Gl√§ttungsmodelle 2. Ordnung ber√ºcksichtigen zudem Trends bei der Prognose und h√§tten auf dem Datensatz eventuell besser performt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) ARIMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Autoregressive-moving-average Modell konnte mit den Leistungen der maschinellen Lernmodelle mithalten, obwohl es eigentlich nicht f√ºr station√§re Zeitreihen optimiert ist. Durch die n√∂tige Trendbereinigung, k√∂nnte Prognoseg√ºte verlorengegangen sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) & 6) MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse zeigen, dass bereits simple Netzstrukturen in der Lage sind, Zeitreihen gut anzun√§hern. Die Komplexit√§t von mehrschichtigen Perzeptren l√§sst sich dabei durch zus√§tzliche Eingabevariablen erh√∂hen. So hat das Hinzuf√ºgen der Clusteringsergebnisse die Vorhersagegenauigkeit leicht verbessert. Offen bleibt, wie der Einfluss √∂konomischer und soziodemographischer Faktoren gewesen w√§re, h√§tte man die Daten des Statistischen Bundesamtes direkt dem MLP √ºbergeben. Geographische Faktoren, wie zum Beispiel die Nachbarschaft der Landkreise untereinander oder Grenzen zu anderen L√§ndern, sind ein weiterer Ansatzpunkt, der im Umfang dieses Projektes nicht untersucht werden konnte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W√§hrend des Lernens ist aufgefallen, dass zu viele Trainingsbeispiele mit null F√§llen als Zielvariable, die Vorhersage auf den Testdaten verzerren. Da die zeitliche Anordnung der Daten f√ºr ein MLP nicht relevant ist konnten diese entfernt werden. Die Vorhersagen f√ºr Landkreise mit den absolut h√∂chsten Fallzahlen waren eher ungenau. Dies l√§sst sich durch deren Unterrepr√§sentation in den Trainingsdaten erkl√§ren. Hier w√§re ein Feature Scaling angebracht gewesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die LSTM-Zelle als komplexestes Modell hat die besten Evaluierungswerte auf den Testdaten erreicht. Das hier angewendete Feature Scaling hatte daran jedoch wahrscheinlich erheblichen Anteil. Es l√§sst sich daher nicht mit Sicherheit sagen, ob die Performanz durch die Modellarchitektur oder die Datenvorverarbeitung erreicht wurde. Die These *More data usually beats better algorithm* scheint hier zu halten. Allgemein gelingt es Rekurrenten Neuronalen Netzen nicht, statische Features, wie zum Beispiel die demographischen Information zu den Landkreisen, mit in die Vorhersage einzubeziehen (vgl. [Miebs et al. 2020](https://www.researchgate.net/publication/338964048_Efficient_Strategies_of_Static_Features_Incorporation_into_the_Recurrent_Neural_Network)). Alternativ h√§tte man hier ein Auxiliary Layer (f√ºr den statischen Eingabevektor) in einer sp√§teren Netzschicht einf√ºgen k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es l√§sst sich festhalten, dass mit den genutzen Modellen und Methoden mehr in die breite als in die tiefe Modellbildung gearbeitet wurde. Die Parameter der Modelle wurden gr√∂√ütenteils stichprobenhaft optimiert. Mit einer Grid Search w√§re hier sicherlich noch Potenzial entfaltbar gewesen. Unsere begrenzte Vorerfahrung im Umgang mit Zeitreihendaten machten diesen generischen Ansatz jedoch notwendig. Das Projekt versteht sich daher als Einstieg und √úberblick in die Vorhersage von Zeitreihen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund der eher simplen Modellarchitekturen und der begrenzten Vielfalt an genutzten Daten liegt es Nahe, dass die Modelle st√§rker zu Under- als zu Overfitting neigen. Bei den maschinellen Lernmodellen wurde die Trainingsepochenanzahl (manuell) so gew√§hlt, dass das Training (ungef√§hr) bei Stagnation des Trainingsfehlers endet. Eine automatische Early-Stopping-Implementierung w√§re angebrachter gewesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erw√§hnenswert ist zudem, dass die Woche der Multi-Period-Vorhersage neben einem Wochenende noch zwei weitere Feiertage enth√§lt - Karfreitag und Ostermontag. Die Anzahl gemeldeter F√§lle w√§hrend arbeitsfreien Tagen ist niedriger, da Testzentren und Gesundheits√§mter w√§hrend dieser Zeit nur eingeschr√§nkt arbeiten. Dies k√∂nnte die Evaluierungsergebnisse zum Vorzug von Modellen mit eher niedrigen Fallzahlen-Vorhersagen verzerrt haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das RNN-Modell wird f√ºr die die weitere Verwendung in einer Webanwendung ausgew√§hlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
